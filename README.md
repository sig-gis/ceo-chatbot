# ceo-chatbot
Project setup helper (LLM chatbot) for CEO

# ðŸ—ºï¸ Navigating the repo

```{bash}
ceo-chatbot/
â”œâ”€â”€ .venv/                    # uv python virtual environment directory (not tracked; created on first `uv sync` or `uv run`)
â”œâ”€â”€ conf/                     # Configuration files for script arguments (YAML, JSON)
â”‚   â”œâ”€â”€ base/                 # Global/shared configuration files tracked in repo
â”‚   â”‚   â”œâ”€â”€ prompts.yml       # Prompt configuration
â”‚   â”‚   â””â”€â”€ rag_config.yml    # RAG configuration: models, vectorstore, prompts...
â”‚   â””â”€â”€ local/                # Personal/local configs (excluded from version control)
â”‚
â”œâ”€â”€ data/                     # Project data directory (not tracked in repo)
â”‚
â”œâ”€â”€ demo/                     # Try ceo-chatbot in a streamlit app
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks for development, prototyping, demos
â”‚
â”œâ”€â”€ src/                      # Source code (modules and utilities imported by scripts) and scripts
â”‚   â””â”€â”€ ceo_chatbot
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py               # Utilities for loading confs in conf/base/
â”‚       â”‚
â”‚       â”œâ”€â”€ ingest                  # Data ingestion pipeline: loaders.py, chunking.py, embeddings.py -> index_builder.py
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ chunking.py         # Utilities for splitting documents into chunks
â”‚       â”‚   â”œâ”€â”€ embeddings.py       # Utilities for defining embedding model
â”‚       â”‚   â”œâ”€â”€ index_builder.py    # Define data ingestion pipeline
â”‚       â”‚   â””â”€â”€ loaders.py          # Utilities for loading dataset
â”‚       â”‚
â”‚       â””â”€â”€ rag                     # RAG pipeline: llm.py, retriever.py -> pipeline.py
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ llm.py              # Utilities for defining reader model
â”‚           â”œâ”€â”€ pipeline.py         # Define RAG pipeline
â”‚           â””â”€â”€ retriever.py        # Utilities for doc retrieval and similarity search
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_index.py        # Data ingestion pipeline runner (offline); chunk, embed, build vector store
â”‚   â””â”€â”€ ...             
â”‚
â”œâ”€â”€ tests/                    # Unit and integration tests
â”‚
â”œâ”€â”€ .gitignore                
â”œâ”€â”€ .python-version           # Python version used by uv environment manager
â”œâ”€â”€ pyproject.toml            # Metadata about the project (for uv)
â”œâ”€â”€ uv.lock                   # Locked dependency versions 
â””â”€â”€ README.md                 

```


# ðŸš€ Getting Started

## 1. Clone the repo

SSH: 
```{bash}
git clone git@github.com:sig-gis/ceo-chatbot.git
```

HTTPS:
```{bash}
git clone https://github.com/sig-gis/ceo-chatbot.git
```

## 2. Manage dependencies with `uv`
   
This app uses uv for dependency managment. 
[Read more about uv in the docs.](https://docs.astral.sh/uv/getting-started/) 

### Install `uv`:

macOS/Linux
```{bash}
curl -LsSf https://astral.sh/uv/install.sh | sh
```

See the [uv installation docs for Windows installation instructions](https://docs.astral.sh/uv/getting-started/installation/#__tabbed_1_2)


Also see [CONTRIBUTING.md](CONTRIBUTING.md) for more detail on developing with `uv` in this project. 


## 3. Install ceo-chatbot 

Install the ceo-chatbot package locally in editable mode.

From the project root: 

```{bash}
uv pip install -e .
```

## 4. (offline) Build vector DB

For local development, the knowledge corpus must be set up one time.

If using a gated model such as [google/embeddinggemma-300m](https://huggingface.co/google/embeddinggemma-300m), 

1. Request access to the model on its Hugging Face model page (access is granted instantly)
2. Generate an access token: Profile > Settings > Access Tokens > + Create new token > Token type Read > Create token
3. Run the following `hf` cli command in your terminal and paste your HF access token when prompted

```{bash}
uv run hf auth login

```

Build the vector DB:

```{bash}
uv run scripts/build_index.py
```

Stay tuned! A planned future version will automate building the vector DB.

## 5. Run a demo chat UI

Launch a basic streamlit application to demo `ceo-chatbot` in a chat UI. 

```{bash}
uv run streamlit run demo/chat_app.py
```
